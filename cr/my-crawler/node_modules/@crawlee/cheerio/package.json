{
    "name": "@crawlee/cheerio",
    "version": "3.0.4",
    "description": "The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.",
    "engines": {
        "node": ">=16.0.0"
    },
    "main": "./index.js",
    "module": "./index.mjs",
    "types": "./index.d.ts",
    "exports": {
        ".": {
            "import": "./index.mjs",
            "require": "./index.js",
            "types": "./index.d.ts"
        },
        "./package.json": "./package.json"
    },
    "keywords": [
        "apify",
        "headless",
        "chrome",
        "puppeteer",
        "crawler",
        "scraper"
    ],
    "author": {
        "name": "Apify",
        "email": "support@apify.com",
        "url": "https://apify.com"
    },
    "contributors": [
        "Jan Curn <jan@apify.com>",
        "Marek Trunkat <marek@apify.com>",
        "Ondra Urban <ondra@apify.com>"
    ],
    "license": "Apache-2.0",
    "repository": {
        "type": "git",
        "url": "git+https://github.com/apify/crawlee"
    },
    "bugs": {
        "url": "https://github.com/apify/crawlee/issues"
    },
    "homepage": "https://crawlee.dev",
    "scripts": {
        "build": "npm run clean && npm run compile && npm run copy",
        "clean": "rimraf ./dist",
        "compile": "tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs",
        "copy": "ts-node -T ../../scripts/copy.ts"
    },
    "publishConfig": {
        "access": "public"
    },
    "dependencies": {
        "@crawlee/http": "^3.0.4",
        "@crawlee/types": "^3.0.4",
        "cheerio": "1.0.0-rc.12",
        "htmlparser2": "^8.0.1"
    }
}
