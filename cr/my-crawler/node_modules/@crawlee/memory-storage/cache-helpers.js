"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.findRequestQueueByPossibleId = exports.findOrCacheKeyValueStoreByPossibleId = exports.findOrCacheDatasetByPossibleId = void 0;
const tslib_1 = require("tslib");
const promises_1 = require("node:fs/promises");
const node_path_1 = require("node:path");
const mime_types_1 = tslib_1.__importDefault(require("mime-types"));
const utils_1 = require("./utils");
const uuidRegex = /[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}/i;
async function findOrCacheDatasetByPossibleId(client, entryNameOrId) {
    // First check memory cache
    const found = client.datasetClientsHandled.find((store) => store.id === entryNameOrId || store.name?.toLowerCase() === entryNameOrId.toLowerCase());
    if (found) {
        return found;
    }
    const datasetDir = (0, node_path_1.resolve)(client.datasetsDirectory, entryNameOrId);
    try {
        // Check if directory exists
        await (0, promises_1.access)(datasetDir);
    }
    catch {
        return undefined;
    }
    // Access the dataset folder
    const directoryEntries = await (0, promises_1.opendir)(datasetDir);
    let id;
    let name;
    let itemCount = 0;
    const entries = new Map();
    let createdAt = new Date();
    let accessedAt = new Date();
    let modifiedAt = new Date();
    let hasSeenMetadataFile = false;
    for await (const entry of directoryEntries) {
        if (entry.isFile()) {
            if (entry.name === '__metadata__.json') {
                hasSeenMetadataFile = true;
                // we have found the store metadata file, build out information based on it
                const metadata = JSON.parse(await (0, promises_1.readFile)((0, node_path_1.resolve)(datasetDir, entry.name), 'utf8'));
                id = metadata.id;
                name = metadata.name;
                itemCount = metadata.itemCount;
                createdAt = new Date(metadata.createdAt);
                accessedAt = new Date(metadata.accessedAt);
                modifiedAt = new Date(metadata.modifiedAt);
                continue;
            }
            const entryContent = JSON.parse(await (0, promises_1.readFile)((0, node_path_1.resolve)(datasetDir, entry.name), 'utf8'));
            const entryName = entry.name.split('.')[0];
            entries.set(entryName, entryContent);
            if (!hasSeenMetadataFile) {
                itemCount++;
            }
        }
    }
    if (id === undefined && name === undefined) {
        const isUuid = uuidRegex.test(entryNameOrId);
        if (isUuid) {
            id = entryNameOrId;
        }
        else {
            name = entryNameOrId;
        }
    }
    const newClient = new dataset_1.DatasetClient({
        baseStorageDirectory: client.datasetsDirectory,
        client,
        id,
        name,
    });
    // Overwrite properties
    newClient.accessedAt = accessedAt;
    newClient.createdAt = createdAt;
    newClient.modifiedAt = modifiedAt;
    newClient.itemCount = itemCount;
    for (const [entryId, content] of entries) {
        // eslint-disable-next-line dot-notation
        newClient['datasetEntries'].set(entryId, { ...content });
    }
    client.datasetClientsHandled.push(newClient);
    return newClient;
}
exports.findOrCacheDatasetByPossibleId = findOrCacheDatasetByPossibleId;
async function findOrCacheKeyValueStoreByPossibleId(client, entryNameOrId) {
    // First check memory cache
    const found = client.keyValueStoresHandled.find((store) => store.id === entryNameOrId || store.name?.toLowerCase() === entryNameOrId.toLowerCase());
    if (found) {
        return found;
    }
    const keyValueStoreDir = (0, node_path_1.resolve)(client.keyValueStoresDirectory, entryNameOrId);
    try {
        // Check if directory exists
        await (0, promises_1.access)(keyValueStoreDir);
    }
    catch {
        return undefined;
    }
    // Access the key value store folder
    const directoryEntries = await (0, promises_1.opendir)(keyValueStoreDir);
    let id;
    let name;
    let createdAt = new Date();
    let accessedAt = new Date();
    let modifiedAt = new Date();
    const internalRecords = new Map();
    for await (const entry of directoryEntries) {
        if (entry.isFile()) {
            if (entry.name === '__metadata__.json') {
                // we have found the store metadata file, build out information based on it
                const metadata = JSON.parse(await (0, promises_1.readFile)((0, node_path_1.resolve)(keyValueStoreDir, entry.name), 'utf8'));
                id = metadata.id;
                name = metadata.name;
                createdAt = new Date(metadata.createdAt);
                accessedAt = new Date(metadata.accessedAt);
                modifiedAt = new Date(metadata.modifiedAt);
                continue;
            }
            if (entry.name.includes('.__metadata__.')) {
                // This is an entry's metadata file, we can use it to create/extend the record
                const metadata = JSON.parse(await (0, promises_1.readFile)((0, node_path_1.resolve)(keyValueStoreDir, entry.name), 'utf8'));
                const newRecord = {
                    ...internalRecords.get(metadata.key),
                    ...metadata,
                };
                internalRecords.set(metadata.key, newRecord);
                continue;
            }
            const fileContent = await (0, promises_1.readFile)((0, node_path_1.resolve)(keyValueStoreDir, entry.name));
            const fileExtension = (0, node_path_1.extname)(entry.name);
            const contentType = mime_types_1.default.contentType(entry.name) || 'text/plain';
            const extension = mime_types_1.default.extension(contentType);
            let finalFileContent = fileContent;
            if (!fileExtension) {
                utils_1.memoryStorageLog.warning([
                    `Key-value entry "${entry.name}" for store ${entryNameOrId} does not have a file extension, assuming it as text.`,
                    'If you want to have correct interpretation of the file, you should add a file extension to the entry.',
                ].join('\n'));
                finalFileContent = fileContent.toString('utf8');
            }
            else if (contentType.includes('application/json')) {
                const stringifiedJson = fileContent.toString('utf8');
                try {
                    // Try parsing the JSON ahead of time (not ideal but solves invalid files being loaded into stores)
                    JSON.parse(stringifiedJson);
                    finalFileContent = stringifiedJson;
                }
                catch {
                    utils_1.memoryStorageLog.warning(`Key-value entry "${entry.name}" for store ${entryNameOrId} has invalid JSON content and will be ignored from the store.`);
                    continue;
                }
            }
            else if (contentType.includes('text/plain')) {
                finalFileContent = fileContent.toString('utf8');
            }
            const nameSplit = entry.name.split('.');
            if (fileExtension) {
                nameSplit.pop();
            }
            const key = nameSplit.join('.');
            const newRecord = {
                key,
                extension,
                value: finalFileContent,
                contentType,
                ...internalRecords.get(key),
            };
            internalRecords.set(key, newRecord);
        }
    }
    if (id === undefined && name === undefined) {
        const isUuid = uuidRegex.test(entryNameOrId);
        if (isUuid) {
            id = entryNameOrId;
        }
        else {
            name = entryNameOrId;
        }
    }
    const newClient = new key_value_store_1.KeyValueStoreClient({
        baseStorageDirectory: client.keyValueStoresDirectory,
        client,
        id,
        name,
    });
    // Overwrite properties
    newClient.accessedAt = accessedAt;
    newClient.createdAt = createdAt;
    newClient.modifiedAt = modifiedAt;
    for (const [key, record] of internalRecords) {
        // eslint-disable-next-line dot-notation
        newClient['keyValueEntries'].set(key, { ...record });
    }
    client.keyValueStoresHandled.push(newClient);
    return newClient;
}
exports.findOrCacheKeyValueStoreByPossibleId = findOrCacheKeyValueStoreByPossibleId;
async function findRequestQueueByPossibleId(client, entryNameOrId) {
    // First check memory cache
    const found = client.requestQueuesHandled.find((store) => store.id === entryNameOrId || store.name?.toLowerCase() === entryNameOrId.toLowerCase());
    if (found) {
        return found;
    }
    const requestQueueDir = (0, node_path_1.resolve)(client.requestQueuesDirectory, entryNameOrId);
    try {
        // Check if directory exists
        await (0, promises_1.access)(requestQueueDir);
    }
    catch {
        return undefined;
    }
    // Access the request queue folder
    const directoryEntries = await (0, promises_1.opendir)(requestQueueDir);
    let id;
    let name;
    let createdAt = new Date();
    let accessedAt = new Date();
    let modifiedAt = new Date();
    let pendingRequestCount = 0;
    let handledRequestCount = 0;
    const entries = [];
    for await (const entry of directoryEntries) {
        if (entry.isFile()) {
            switch (entry.name) {
                case '__metadata__.json': {
                    // we have found the store metadata file, build out information based on it
                    const metadata = JSON.parse(await (0, promises_1.readFile)((0, node_path_1.resolve)(requestQueueDir, entry.name), 'utf8'));
                    id = metadata.id;
                    name = metadata.name;
                    createdAt = new Date(metadata.createdAt);
                    accessedAt = new Date(metadata.accessedAt);
                    modifiedAt = new Date(metadata.modifiedAt);
                    pendingRequestCount = metadata.pendingRequestCount;
                    handledRequestCount = metadata.handledRequestCount;
                    break;
                }
                default: {
                    const request = JSON.parse(await (0, promises_1.readFile)((0, node_path_1.resolve)(requestQueueDir, entry.name), 'utf8'));
                    entries.push(request);
                }
            }
        }
    }
    if (id === undefined && name === undefined) {
        const isUuid = uuidRegex.test(entryNameOrId);
        if (isUuid) {
            id = entryNameOrId;
        }
        else {
            name = entryNameOrId;
        }
    }
    const newClient = new request_queue_1.RequestQueueClient({
        baseStorageDirectory: client.requestQueuesDirectory,
        client,
        id,
        name,
    });
    // Overwrite properties
    newClient.accessedAt = accessedAt;
    newClient.createdAt = createdAt;
    newClient.modifiedAt = modifiedAt;
    newClient.pendingRequestCount = pendingRequestCount;
    newClient.handledRequestCount = handledRequestCount;
    for (const entry of entries) {
        // eslint-disable-next-line dot-notation
        newClient['requests'].set(entry.id, entry);
    }
    client.requestQueuesHandled.push(newClient);
    return newClient;
}
exports.findRequestQueueByPossibleId = findRequestQueueByPossibleId;
/* eslint-disable import/first -- Fixing circulars */
const dataset_1 = require("./resource-clients/dataset");
const key_value_store_1 = require("./resource-clients/key-value-store");
const request_queue_1 = require("./resource-clients/request-queue");
//# sourceMappingURL=cache-helpers.js.map